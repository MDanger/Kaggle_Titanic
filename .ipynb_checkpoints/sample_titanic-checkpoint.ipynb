{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "76709bc3-414b-4664-bc87-98ccc7d12872",
    "_uuid": "6b9d087f200f1114649fc55ab10aa3c859119c95"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from IPython import display\n",
    "\n",
    "# common model algorithms\n",
    "from sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# common model helpers\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn import feature_selection\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "\n",
    "# visiualisation\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pylab\n",
    "import seaborn as sns\n",
    "from pandas.tools.plotting import scatter_matrix\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import time\n",
    "\n",
    "%matplotlib inline\n",
    "mpl.style.use('ggplot')\n",
    "sns.set_style('white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "72143c82-b2fd-448b-a580-471a759968bc",
    "_uuid": "bdddb4d734520a436fa685ecd26e73fc976a1bb9"
   },
   "source": [
    "**Load Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "73cb7595-18e6-4ce2-a91d-7b3618e3c728",
    "_uuid": "d1aac0061375270939f91f04e55f76c6fde8d13a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.6+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import training and test set\n",
    "data_raw = pd.read_csv('../train.csv')\n",
    "data_val = pd.read_csv('../test.csv')\n",
    "\n",
    "# Make a copy of the training set to wrangle\n",
    "data1 = data_raw.copy(deep=True)\n",
    "\n",
    "# Put both in a list so we can clean both datasets at once\n",
    "data_cleaner = [data1, data_val]\n",
    "\n",
    "# Get an overview of the data\n",
    "print(data_raw.info())\n",
    "data1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "71810c14-b8bf-4e74-b6e0-334329b4a90e",
    "_uuid": "d26688385a540bc5a59171d7d21743c5107db0ca"
   },
   "source": [
    "**Get overview of data and missing values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_cell_guid": "7b451cbc-21e6-46ab-9b52-a768bdac708a",
    "_uuid": "0728f62db23ba6cdf52c4f000f8c449be467d5e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set null values\n",
      " PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age            177\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          687\n",
      "Embarked         2\n",
      "dtype: int64\n",
      "--------------------\n",
      "Test set null values\n",
      " PassengerId      0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age             86\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             1\n",
      "Cabin          327\n",
      "Embarked         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for null values in training and test set\n",
    "print('Training set null values\\n', data1.isnull().sum())\n",
    "print('-'*20)\n",
    "print('Test set null values\\n', data_val.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "334cd328-4280-4a95-84d8-1118dcf2e44f",
    "_uuid": "d441f44dd64367a56b79126699cf105c6ac2e708"
   },
   "source": [
    "test df null values: Age, Cabin and Embarked<br>\n",
    "training df null values: Age, Fare, Cabin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "d539b0f9-40b6-4440-ac36-28a59cb07b45",
    "_uuid": "8ed11c9b25f3dd95c55d49927a7c6da77ef9e042"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>204</td>\n",
       "      <td>889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>891</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>681</td>\n",
       "      <td>NaN</td>\n",
       "      <td>147</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mockler, Miss. Helen Mary \"Ellie\"</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1601</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C23 C25 C27</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>577</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.204208</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49.693429</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.910400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.454200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>512.329200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        PassengerId    Survived      Pclass  \\\n",
       "count    891.000000  891.000000  891.000000   \n",
       "unique          NaN         NaN         NaN   \n",
       "top             NaN         NaN         NaN   \n",
       "freq            NaN         NaN         NaN   \n",
       "mean     446.000000    0.383838    2.308642   \n",
       "std      257.353842    0.486592    0.836071   \n",
       "min        1.000000    0.000000    1.000000   \n",
       "25%      223.500000    0.000000    2.000000   \n",
       "50%      446.000000    0.000000    3.000000   \n",
       "75%      668.500000    1.000000    3.000000   \n",
       "max      891.000000    1.000000    3.000000   \n",
       "\n",
       "                                     Name   Sex         Age       SibSp  \\\n",
       "count                                 891   891  714.000000  891.000000   \n",
       "unique                                891     2         NaN         NaN   \n",
       "top     Mockler, Miss. Helen Mary \"Ellie\"  male         NaN         NaN   \n",
       "freq                                    1   577         NaN         NaN   \n",
       "mean                                  NaN   NaN   29.699118    0.523008   \n",
       "std                                   NaN   NaN   14.526497    1.102743   \n",
       "min                                   NaN   NaN    0.420000    0.000000   \n",
       "25%                                   NaN   NaN   20.125000    0.000000   \n",
       "50%                                   NaN   NaN   28.000000    0.000000   \n",
       "75%                                   NaN   NaN   38.000000    1.000000   \n",
       "max                                   NaN   NaN   80.000000    8.000000   \n",
       "\n",
       "             Parch Ticket        Fare        Cabin Embarked  \n",
       "count   891.000000    891  891.000000          204      889  \n",
       "unique         NaN    681         NaN          147        3  \n",
       "top            NaN   1601         NaN  C23 C25 C27        S  \n",
       "freq           NaN      7         NaN            4      644  \n",
       "mean      0.381594    NaN   32.204208          NaN      NaN  \n",
       "std       0.806057    NaN   49.693429          NaN      NaN  \n",
       "min       0.000000    NaN    0.000000          NaN      NaN  \n",
       "25%       0.000000    NaN    7.910400          NaN      NaN  \n",
       "50%       0.000000    NaN   14.454200          NaN      NaN  \n",
       "75%       0.000000    NaN   31.000000          NaN      NaN  \n",
       "max       6.000000    NaN  512.329200          NaN      NaN  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for outliers / weird values\n",
    "data_raw.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "4fb29dbd-fbe9-415f-86bd-14d509a56c7b",
    "_uuid": "caf15222b0dffd7eab92e25ab241a7d1b3fae48b"
   },
   "source": [
    "## Complete Data\n",
    "\n",
    "**Data to Complete**<br>\n",
    "Age: Use median to compute missing values<br>\n",
    "Embarked: Use mode to complete missing values<br>\n",
    "Fare: Use median to complete missing fare\n",
    "\n",
    "**Data to Drop**<br>\n",
    "Cabin: Too many missing values, furthermore doesnt make sense to use this as a predictor for survival rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_cell_guid": "80b06bad-7654-4d6d-bb06-1c62feebb991",
    "_uuid": "e2886d249c4e5d7fe235fbb024b371cd2cdb3b00"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "labels ['PassengerId' 'Cabin' 'Ticket'] not contained in axis",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-ab2feea24127>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# drop columns in test set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mdrop_columns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'PassengerId'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Cabin'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Ticket'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mdata1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdrop_columns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m# check if data completed for both training and test set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   2528\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2529\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2530\u001b[1;33m                 \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2531\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2532\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[1;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[0;32m   2560\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2561\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2562\u001b[1;33m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2563\u001b[0m             \u001b[0mdropped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2564\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\Lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   3742\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'ignore'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3743\u001b[0m                 raise ValueError('labels %s not contained in axis' %\n\u001b[1;32m-> 3744\u001b[1;33m                                  labels[mask])\n\u001b[0m\u001b[0;32m   3745\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3746\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: labels ['PassengerId' 'Cabin' 'Ticket'] not contained in axis"
     ]
    }
   ],
   "source": [
    "# Complete data for both training and test sets\n",
    "for dataset in data_cleaner:\n",
    "    dataset['Age'].fillna(value=dataset['Age'].median(), inplace=True)\n",
    "    dataset['Embarked'].fillna(value=dataset['Embarked'].mode()[0], inplace=True)\n",
    "    dataset['Fare'].fillna(value=dataset['Fare'].median(), inplace=True)\n",
    "\n",
    "# drop columns in test set\n",
    "drop_columns = ['PassengerId', 'Cabin', 'Ticket']\n",
    "data1.drop(drop_columns, axis=1, inplace=True)\n",
    "\n",
    "# check if data completed for both training and test set\n",
    "print(data1.isnull().sum())\n",
    "print('-'*20)\n",
    "print(data_val.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "f40a1506-6cf4-48df-bdc9-e260c871b3cc",
    "_uuid": "4ac25120f23923d7b7f1bb783eb15ab4cc5d19a7"
   },
   "source": [
    "## Create (Feature Engineering)\n",
    "\n",
    "**New Features To Create**<br>\n",
    "FamilySize: Parch + Sibsp + 1<br>\n",
    "IsAlone: 1 if alone else 0 if there are siblings<br>\n",
    "Title feature: Take out the titles from the names to see if people who have titles have higher chance of survival<br>\n",
    "\n",
    "**Numerical features that can be converted to categorial**<br>\n",
    "FareBin: Cut Fare into 4 equal bins<br>\n",
    "AgeBin: Cut Age into 5 bins "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_cell_guid": "13ef2f1d-b34d-4db2-a129-895f8065abf0",
    "_uuid": "b396ac3f127b24335b082f76197074138c2b6f6c"
   },
   "outputs": [],
   "source": [
    "# Create new features in both the training and test set\n",
    "\n",
    "for dataset in data_cleaner:\n",
    "    # Create feature for FamilySize\n",
    "    dataset['FamilySize'] = dataset['Parch'] + dataset['SibSp'] + 1\n",
    "    \n",
    "    # Create feature for IsAlone. 1 for alone, 0 if there have siblings or children\n",
    "    dataset['IsAlone'] = 1\n",
    "    dataset['IsAlone'].loc[dataset['FamilySize'] > 1] = 0\n",
    "    \n",
    "    # Create Title feature\n",
    "    dataset['Title'] = dataset['Name'].str.split(', ', expand=True)[1].str.split('.', expand=True)[0]\n",
    "    \n",
    "    # Create Age Bins\n",
    "    dataset['AgeBin'] = pd.cut(dataset['Age'], 5)\n",
    "    \n",
    "    # Create Fare Bins\n",
    "    dataset['FareBin'] = pd.qcut(dataset['Fare'], 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_cell_guid": "91da9579-614c-4657-b22c-cc0746ef01c2",
    "_uuid": "18caffda663330f2872177f344994126aef8c968"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mr        517\n",
      "Miss      185\n",
      "Mrs       126\n",
      "Master     40\n",
      "Misc       23\n",
      "Name: Title, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Replace wrong designations\n",
    "data1['Title'] = data1['Title'].replace({'Ms': 'Miss', 'Mme': 'Mrs', 'Mlle':'Miss'})\n",
    "\n",
    "# Group uncommon designations as misc\n",
    "stat_min = 10\n",
    "title_names = data1['Title'].value_counts() < stat_min\n",
    "\n",
    "data1['Title'] = data1['Title'].apply(lambda x: 'Misc' if title_names.loc[x] == True else x)\n",
    "print(data1['Title'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "9d32def2-8c79-46df-af4a-9abb98890e66",
    "_uuid": "1330f9b8a3d874ed8fca8d9cc48fccd445c25463"
   },
   "source": [
    "## Convert Features \n",
    "\n",
    "Convert text data to ordinal (LabelEncoder), then convert to OneHot (pd.get_dummies)\n",
    "\n",
    "**Categorical Data**: Sex, Pclass, Embarked, Title, SibSp, Parch, Age, Fare,FamilySize, FamilySize, IsAlone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_cell_guid": "e9710569-c056-4f06-85ea-076b4f0f730c",
    "_uuid": "d346d05cc491e685c1ce3f0a21a88d4026889069"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>IsAlone</th>\n",
       "      <th>Title</th>\n",
       "      <th>AgeBin</th>\n",
       "      <th>FareBin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Mr</td>\n",
       "      <td>(16.336, 32.252]</td>\n",
       "      <td>(-0.001, 7.91]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>(32.252, 48.168]</td>\n",
       "      <td>(31.0, 512.329]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Miss</td>\n",
       "      <td>(16.336, 32.252]</td>\n",
       "      <td>(7.91, 14.454]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>(32.252, 48.168]</td>\n",
       "      <td>(31.0, 512.329]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Mr</td>\n",
       "      <td>(32.252, 48.168]</td>\n",
       "      <td>(7.91, 14.454]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass                                               Name  \\\n",
       "0         0       3                            Braund, Mr. Owen Harris   \n",
       "1         1       1  Cumings, Mrs. John Bradley (Florence Briggs Th...   \n",
       "2         1       3                             Heikkinen, Miss. Laina   \n",
       "3         1       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)   \n",
       "4         0       3                           Allen, Mr. William Henry   \n",
       "\n",
       "      Sex   Age  SibSp  Parch     Fare Embarked  FamilySize  IsAlone Title  \\\n",
       "0    male  22.0      1      0   7.2500        S           2        0    Mr   \n",
       "1  female  38.0      1      0  71.2833        C           2        0   Mrs   \n",
       "2  female  26.0      0      0   7.9250        S           1        1  Miss   \n",
       "3  female  35.0      1      0  53.1000        S           2        0   Mrs   \n",
       "4    male  35.0      0      0   8.0500        S           1        1    Mr   \n",
       "\n",
       "             AgeBin          FareBin  \n",
       "0  (16.336, 32.252]   (-0.001, 7.91]  \n",
       "1  (32.252, 48.168]  (31.0, 512.329]  \n",
       "2  (16.336, 32.252]   (7.91, 14.454]  \n",
       "3  (32.252, 48.168]  (31.0, 512.329]  \n",
       "4  (32.252, 48.168]   (7.91, 14.454]  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_cell_guid": "faf4e7d5-4a50-472f-bfbb-b422c13dacbb",
    "_uuid": "dbd855499a1934be086f58d77c4b0748e4bf4340"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original X Y:  ['Survived', 'Sex', 'Pclass', 'Embarked', 'Title', 'SibSp', 'Parch', 'Age', 'Fare', 'FamilySize', 'IsAlone'] \n",
      "\n",
      "Bin X Y:  ['Survived', 'Sex_Code', 'Pclass', 'Embarked_Code', 'Title_Code', 'FamilySize', 'AgeBin_Code', 'FareBin_Code'] \n",
      "\n",
      "Dummy X Y:  ['Survived', 'Pclass', 'SibSp', 'Parch', 'Age', 'Fare', 'FamilySize', 'IsAlone', 'Sex_female', 'Sex_male', 'Embarked_C', 'Embarked_Q', 'Embarked_S', 'Title_Master', 'Title_Misc', 'Title_Miss', 'Title_Mr', 'Title_Mrs'] \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>IsAlone</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Title_Master</th>\n",
       "      <th>Title_Misc</th>\n",
       "      <th>Title_Miss</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass  SibSp  Parch   Age     Fare  FamilySize  IsAlone  Sex_female  \\\n",
       "0       3      1      0  22.0   7.2500           2        0           0   \n",
       "1       1      1      0  38.0  71.2833           2        0           1   \n",
       "2       3      0      0  26.0   7.9250           1        1           1   \n",
       "3       1      1      0  35.0  53.1000           2        0           1   \n",
       "4       3      0      0  35.0   8.0500           1        1           0   \n",
       "\n",
       "   Sex_male  Embarked_C  Embarked_Q  Embarked_S  Title_Master  Title_Misc  \\\n",
       "0         1           0           0           1             0           0   \n",
       "1         0           1           0           0             0           0   \n",
       "2         0           0           0           1             0           0   \n",
       "3         0           0           0           1             0           0   \n",
       "4         1           0           0           1             0           0   \n",
       "\n",
       "   Title_Miss  Title_Mr  Title_Mrs  \n",
       "0           0         1          0  \n",
       "1           0         0          1  \n",
       "2           1         0          0  \n",
       "3           0         0          1  \n",
       "4           0         1          0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# code categorical data\n",
    "label = LabelEncoder()\n",
    "\n",
    "for dataset in data_cleaner:\n",
    "    dataset['Sex_Code'] = label.fit_transform(dataset['Sex'])\n",
    "    dataset['Embarked_Code'] = label.fit_transform(dataset['Embarked'])\n",
    "    dataset['Title_Code'] = label.fit_transform(dataset['Title'])\n",
    "    dataset['AgeBin_Code'] = label.fit_transform(dataset['AgeBin'])\n",
    "    dataset['FareBin_Code'] = label.fit_transform(dataset['FareBin'])\n",
    "    \n",
    "# define y variable for target/outcome\n",
    "Target = ['Survived']\n",
    "\n",
    "# define x variable for original features aka feature selection\n",
    "data1_x = ['Sex', 'Pclass', 'Embarked', 'Title', 'SibSp', 'Parch', 'Age', 'Fare', 'FamilySize', 'IsAlone']\n",
    "\n",
    "# pretty name/values for charts\n",
    "data1_x_calc = ['Sex', 'Pclass', 'Embarked_Code', 'Title_Code', 'SibSp', 'Parch', 'Age', 'Fare'] # coded for algo calc\n",
    "\n",
    "data1_xy = Target + data1_x\n",
    "print('Original X Y: ',data1_xy,'\\n' )\n",
    "\n",
    "\n",
    "# define x variables for original with bin features. Categorical coded numerically instead of in words.\n",
    "data1_x_bin = ['Sex_Code', 'Pclass', 'Embarked_Code', 'Title_Code', 'FamilySize', 'AgeBin_Code', 'FareBin_Code']\n",
    "data1_xy_bin = Target + data1_x_bin\n",
    "print('Bin X Y: ', data1_xy_bin, '\\n')\n",
    "\n",
    "\n",
    "# Establish dummy variables\n",
    "data1_dummy = pd.get_dummies(data1[data1_x])\n",
    "data1_x_dummy = data1_dummy.columns.tolist()\n",
    "data1_xy_dummy = Target + data1_x_dummy\n",
    "print('Dummy X Y: ', data1_xy_dummy, '\\n')\n",
    "\n",
    "data1_dummy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_cell_guid": "74d1eedb-a381-4d15-bc69-1b117e646512",
    "_uuid": "7d8307c911d5175066e242d1084b1393ddd9fabd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 21 columns):\n",
      "PassengerId      418 non-null int64\n",
      "Pclass           418 non-null int64\n",
      "Name             418 non-null object\n",
      "Sex              418 non-null object\n",
      "Age              418 non-null float64\n",
      "SibSp            418 non-null int64\n",
      "Parch            418 non-null int64\n",
      "Ticket           418 non-null object\n",
      "Fare             418 non-null float64\n",
      "Cabin            91 non-null object\n",
      "Embarked         418 non-null object\n",
      "FamilySize       418 non-null int64\n",
      "IsAlone          418 non-null int64\n",
      "Title            418 non-null object\n",
      "AgeBin           418 non-null category\n",
      "FareBin          418 non-null category\n",
      "Sex_Code         418 non-null int64\n",
      "Embarked_Code    418 non-null int64\n",
      "Title_Code       418 non-null int64\n",
      "AgeBin_Code      418 non-null int64\n",
      "FareBin_Code     418 non-null int64\n",
      "dtypes: category(2), float64(2), int64(11), object(6)\n",
      "memory usage: 63.1+ KB\n"
     ]
    }
   ],
   "source": [
    "data_val.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "fceeb516-954c-4824-a748-005e95a3b2dd",
    "_uuid": "d0ee4589488c0a9face929613d5efc44e1b165ff"
   },
   "source": [
    "## Split data into training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "42d187bd-af9d-45f1-8470-500d5dcc1e28",
    "_uuid": "c18d1e082bfb267209f8f54e691ee28c06e7699f",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split data into training and test set\n",
    "train1_x, test1_x, train1_y, test1_y = model_selection.train_test_split(data1[data1_x_calc], data1[Target], random_state=0)\n",
    "train1_x_bin, test1_x_bin, train1_y_bin, test1_y_bin = model_selection.train_test_split(data1[data1_x_bin], data1[Target], random_state=0)\n",
    "train1_x_dummy, test1_x_dummy, train1_y_dummy, test1_y_dummy = model_selection.train_test_split(data1_dummy[data1_x_dummy], data1[Target], random_state=0)\n",
    "\n",
    "print('Data1 Shape:', data1.shape)\n",
    "print('Train1 Shape:', train1_x.shape)\n",
    "print('Test1 Shape:', test1_x.shape)\n",
    "\n",
    "train1_x_bin.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "4959430d-5008-4e6f-af33-926c459a5c96",
    "_uuid": "f136362a85b6576abaad0bb040e79b3d4b082d96"
   },
   "source": [
    "## Perform exploratory analysis with statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "25390cdf-fecb-4378-8010-e142ffaffa44",
    "_uuid": "def17a01e813fb28226346bcdc1cc9be9e537e52"
   },
   "source": [
    "Create a pivot table to observe each predictor's correlation with the Target (survival)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "8733026d-f3c8-43d9-b73d-f200b7344cdb",
    "_uuid": "946fecdeb48cac6b91bb202996e31926cf45a776",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Discrete variable correlation by survival using groupby pivot table\n",
    "for x in data1_x:\n",
    "    if data1[x].dtype != 'float64':\n",
    "        print('Survival Correlation by: ', x)\n",
    "        print(data1[[x, Target[0]]].groupby(by=x, as_index=False).mean())\n",
    "        print('-'*40,'\\n')\n",
    "        \n",
    "# Using crosstabs\n",
    "print(pd.crosstab(data1['Title'], data1[Target[0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "88fb643d-fd0b-4a39-996e-c1be7c2eac5d",
    "_uuid": "6523c68274c666e597f3f85320185202787cc508"
   },
   "source": [
    "## Plot numerical continuous variables\n",
    "\n",
    "Look at distribution of numerical continuous variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "d0e5e5d1-13e8-4976-a7a6-155a6dd076d5",
    "_uuid": "688641520b7b0c4c4abadd1195b78c8e8da89275",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,12))\n",
    "0\n",
    "plt.subplot(231)\n",
    "plt.boxplot(data1['Fare'], meanline=True, showmeans=True);\n",
    "plt.xlabel('Fare Boxplot')\n",
    "plt.ylabel('Fare ($)')\n",
    "plt.title('Fare Boxplot')\n",
    "\n",
    "plt.subplot(232)\n",
    "plt.boxplot(data1['Age'], meanline=True, showmeans=True);\n",
    "plt.xlabel('Age Boxplot')\n",
    "plt.ylabel('Age (Years)')\n",
    "plt.title('Age Boxplot')\n",
    "\n",
    "plt.subplot(233)\n",
    "plt.boxplot(data1['FamilySize'], meanline=True, showmeans=True);\n",
    "plt.xlabel('FamilySize Boxplot')\n",
    "plt.ylabel('Family Size (#)')\n",
    "plt.title('Family Boxplot')\n",
    "\n",
    "plt.subplot(234)\n",
    "plt.hist(x=[data1[data1['Survived'] == 1]['Fare'], data1[data1['Survived'] == 0]['Fare']], stacked=True, color=['g', 'r'], label=['Survived', 'Dead'])\n",
    "plt.xlabel('Fare ($)')\n",
    "plt.ylabel('# of Passengers')\n",
    "plt.title('Fare Histogram by Survival')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(235)\n",
    "plt.hist(x=[data1[data1['Survived'] == 1]['Age'], data1[data1['Survived'] == 0]['Age']], stacked=True, color=['g', 'r'], label=['Survived', 'Dead'])\n",
    "plt.xlabel('Age (# of years)')\n",
    "plt.ylabel('# of Passengers')\n",
    "plt.title('Age Histogram by Survival')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(236)\n",
    "plt.hist(x=[data1[data1['Survived'] == 1]['FamilySize'], data1[data1['Survived'] == 0]['FamilySize']], stacked=True, color=['g', 'r'], label=['Survived', 'Dead'])\n",
    "plt.xlabel('Family Size')\n",
    "plt.ylabel('# of Passengers')\n",
    "plt.title('Family Size Histogram by Survival')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "429b5019-5126-4e37-b0ad-9025ccb30db8",
    "_uuid": "c24b8aa13d012da37fad8cb2086c225235bc526f"
   },
   "source": [
    "## Plot categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "050ba3e0-7208-4ff6-93e4-e4fad6d7fe31",
    "_uuid": "b7f1acb51e67ac4ab6173b021e775717e027015f",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, saxis = plt.subplots(2,3,figsize=(16,12))\n",
    "\n",
    "sns.barplot(x= 'Embarked', y= 'Survived', data=data1, ax= saxis[0,0])\n",
    "sns.barplot(x = 'Pclass', y='Survived', data=data1, ax=saxis[0,1])\n",
    "sns.barplot(x = 'IsAlone', y='Survived', data=data1, ax=saxis[0,2], order=[1,0])\n",
    "\n",
    "sns.pointplot(x='FareBin', y='Survived', data=data1, ax=saxis[1,0])\n",
    "sns.pointplot(x='AgeBin', y='Survived', data=data1, ax=saxis[1,1])\n",
    "sns.pointplot(x='FamilySize', y='Survived', data=data1, ax=saxis[1,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a0a77fc1-391a-47aa-86ab-565ca86d008c",
    "_uuid": "b617da8ee2467bb98921ba58bac463d3c11cf1ac"
   },
   "source": [
    "- Passegers from port C had a significantly higher chance of survival\n",
    "- May be multicollinearity, where passengers who had higher fare / class boarding from port C\n",
    "- Passengers from better class higher chance of survival\n",
    "- Passengers who were not alone had a higher chance of survival<br><br>\n",
    "\n",
    "- Passengers who paid higher fares had higher chance of survival. Again, may be multicollinearity between Fare and PClass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e013078b-6ca3-4841-ae21-294beba734ed",
    "_uuid": "11081c26a110f113432ff9885441c04c65b41ada"
   },
   "source": [
    "## Graph distribution of Pclass w.r.t other variables (fare, age, family size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "808558a9-ab71-4cc1-8e84-b6597a95dae1",
    "_uuid": "617f42881c8064e5cbadb077bc0bec3647fa892f",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, (ax1,ax2,ax3) = plt.subplots(1,3, figsize=(14,12))\n",
    "\n",
    "sns.boxplot(x='Pclass', y='Fare', hue='Survived', data=data1, ax=ax1)\n",
    "ax1.set_title('Pclass vs Fare Survival Comparison')\n",
    "\n",
    "sns.violinplot(x='Pclass', y='Age', hue='Survived', data=data1, ax=ax2, split=True)\n",
    "ax2.set_title('Pclass vs Age Survival Comparison')\n",
    "\n",
    "sns.boxplot(x='Pclass', y='FamilySize', hue='Survived', data=data1, ax=ax3)\n",
    "ax3.set_title('Pclass vs Family Size Survival Comparison')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b2d5207d-3392-486c-97a2-4d730e2717a8",
    "_uuid": "1ae23ad84f185be5f691992f2654ec9005989699"
   },
   "source": [
    "- Passengers from higher classes paid a higher fare\n",
    "- Passengers who are older tend to be from higher classes\n",
    "- No clear relationship between FamilySize and PClass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "6fd9ad78-12a9-48d0-929f-aa63e38a8900",
    "_uuid": "78d9c55a476f8d54e30a92e8bad580d2e7b80a34"
   },
   "source": [
    "## Graph Distribution of  Sex Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79420996-5dbe-4fbf-b07d-2c6927ee32e8",
    "_uuid": "80bdabbff83c1fe1e42b3b5cc8af392321005dd3",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# graph distribution of qualitative data: sex\n",
    "\n",
    "fig, qaxis = plt.subplots(1,3,figsize=(14,12))\n",
    "\n",
    "sns.barplot(x = 'Sex', y = 'Survived', hue = 'Embarked', data=data1, ax = qaxis[0])\n",
    "qaxis[0].set_title('Sex vs Embarked Survival Comparison')\n",
    "\n",
    "sns.barplot(x = 'Sex', y = 'Survived', hue = 'Pclass', data=data1, ax = qaxis[1])\n",
    "qaxis[1].set_title('Sex vs Pclass Survival Comparison')\n",
    "\n",
    "sns.barplot(x = 'Sex', y = 'Survived', hue = 'IsAlone', data=data1, ax = qaxis[2])\n",
    "qaxis[2].set_title('Sex vs IsAlone Survival Comparison');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "03e9ec4f-edd9-486b-b810-57f429bae795",
    "_uuid": "42deaac10a6d99bff1836f2bab8af8db766ce452"
   },
   "source": [
    "- Obvious that females had a much higher chance of survival as compared to males"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f278b454-3de0-4731-b75e-a5e8068ab36b",
    "_uuid": "26503443140b8f6715298700f17a4318c76b6ea6",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# More side by side comparisons of FamilySize and Pclass vs the dependent variable\n",
    "\n",
    "fig, (maxis1, maxis2) = plt.subplots(1,2,figsize=(14,12))\n",
    "\n",
    "# family size with survival and sex compare\n",
    "sns.pointplot(x='FamilySize', y='Survived', hue='Sex', data=data1, ax=maxis1, palette={'male': 'blue', 'female': 'pink'},\n",
    "             markers=['*', 'o'], linestyles=['-', '--'])\n",
    "\n",
    "# Pclass with survival and sex compare\n",
    "sns.pointplot(x='Pclass', y='Survived', hue='Sex', data=data1, ax=maxis2, palette={'male': 'blue', 'female': 'pink'},\n",
    "             markers=['*', 'o'], linestyles=['-', '--']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "2eb3fd8d-ed40-464f-8648-a6bbd686380d",
    "_uuid": "9aeb12b85fd0c6acbccf9d74656642fb9e13ed06"
   },
   "source": [
    "- Again clear that females have higher chance of survival\n",
    "- No clear relationship between FamilySize and Survival\n",
    "- Clear relationship between PClass and survival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "94ce08eb-41e6-4f2a-8635-cfd05c33a6bd",
    "_uuid": "d9e3992d3ffa4df60dfb842a5539297b40b2a343",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot distribution of passengers who survived vs died\n",
    "a = sns.FacetGrid(data1, hue='Survived', aspect=4)\n",
    "a.map(sns.kdeplot, 'Age', shade=True)\n",
    "a.set(xlim=(0, data1['Age'].max()))\n",
    "a.add_legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "0994c1b0-4d88-4774-b006-198f586ed1c4",
    "_uuid": "6731c65829e73dd0a02cc9388735f6b79e88e4d0"
   },
   "source": [
    "- Higher proportion of young children (below 15) survived - More survived than died\n",
    "- Lower proportion of middle aged (20 - 35) survived - More died than survived\n",
    "- Above 35, about equal percentages survived and died"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "5e43fc90-dead-4081-9cde-386e0e603685",
    "_uuid": "12516d650051421fd38c5e9c5f69a5bf57e73f8b",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Comparison of Sex, Class, and Age\n",
    "s = sns.FacetGrid(data1, row='Sex', col='Pclass', hue='Survived')\n",
    "s.map(plt.hist, 'Age', alpha=0.5)\n",
    "s.add_legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "c9f183e1-c940-4f57-8178-53cc82ae6b48",
    "_uuid": "a924c4d8167be6800aad56b678dab2ad86d2b690"
   },
   "source": [
    "- We can see that the vast proportion of those who died are **males from 2nd and 3rd class**\n",
    "- Almost all females from the 1st and 2nd classes survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "500a7c23-2959-4d39-92ae-b8c5753c8e06",
    "_uuid": "280a2a6b53ac13df51d99734f52b3318ab8bfd1f",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#correlation heatmap of dataset\n",
    "def correlation_heatmap(df):\n",
    "    _ , ax = plt.subplots(figsize =(14, 12))\n",
    "    colormap = sns.diverging_palette(220, 10, as_cmap = True)\n",
    "    \n",
    "    _ = sns.heatmap(\n",
    "        df.corr(), \n",
    "        cmap = colormap,\n",
    "        square=True, \n",
    "        cbar_kws={'shrink':.9 }, \n",
    "        ax=ax,\n",
    "        annot=True, \n",
    "        linewidths=0.1,vmax=1.0, linecolor='white',\n",
    "        annot_kws={'fontsize':12 }\n",
    "    )\n",
    "    \n",
    "    plt.title('Pearson Correlation of Features', y=1.05, size=15)\n",
    "\n",
    "correlation_heatmap(data1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e6244201-15ba-4566-afd3-6527acb37080",
    "_uuid": "2dd0fa8aa33ef7c35228f28c14d47602d483f4f5"
   },
   "source": [
    "Corr heatmaps shows the following:\n",
    "- Strong negative correlation between PClass and FareBin (higher fare, lower the class)\n",
    "- Strong negative correlation between FareBin_Code and IsAlone\n",
    "- As noted earlier, strong correlation between Sex and Survived\n",
    "- As noted earlier, moderate negative correlation between PClass and Survived\n",
    "- Modete positive correlation between Title and Age. Makes sense\n",
    "\n",
    "Of course, strong correlation between the below features as they were engineered:\n",
    "- SibSp and Parch and the additional features that we derived from them: Family Size and IsAlone\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "4bb17070-3324-4b73-9ecb-e50a00b2305f",
    "_uuid": "0ab4fbfd9303f6252b8809cb602fc580bded17c6"
   },
   "source": [
    "# Model Data\n",
    "\n",
    "Create a table with all the base models, evaluating the CV train and test accuracy, as well as the standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f5c5a234-cb9c-4129-b7de-70bc52dca92d",
    "_uuid": "248d111962a84b48b3dfe5bcad0e6557de947bc4",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Machine Learning Algo Selection and Initialization\n",
    "MLA = [\n",
    "    # Ensemble methods\n",
    "    ensemble.AdaBoostClassifier(),\n",
    "    ensemble.BaggingClassifier(),\n",
    "    ensemble.ExtraTreesClassifier(),\n",
    "    ensemble.GradientBoostingClassifier(),\n",
    "    ensemble.RandomForestClassifier(),\n",
    "    \n",
    "    # Gaussian Process\n",
    "    gaussian_process.GaussianProcessClassifier(),\n",
    "    \n",
    "    #General Linear Models\n",
    "    linear_model.LogisticRegressionCV(),\n",
    "    linear_model.PassiveAggressiveClassifier(),\n",
    "    linear_model.RidgeClassifierCV(),\n",
    "    linear_model.SGDClassifier(),\n",
    "    linear_model.Perceptron(),\n",
    "    \n",
    "    # Naive Bayes\n",
    "    naive_bayes.BernoulliNB(),\n",
    "    naive_bayes.GaussianNB(),\n",
    "    \n",
    "    # Nearest Neighbour\n",
    "    neighbors.KNeighborsClassifier(),\n",
    "    \n",
    "    # SVM\n",
    "    svm.SVC(probability=True),\n",
    "    svm.NuSVC(probability=True),\n",
    "    svm.LinearSVC(),\n",
    "    \n",
    "    # Trees\n",
    "    tree.DecisionTreeClassifier(),\n",
    "    tree.ExtraTreeClassifier(),\n",
    "    \n",
    "    # Discriminant Analysis\n",
    "    discriminant_analysis.LinearDiscriminantAnalysis(),\n",
    "    discriminant_analysis.QuadraticDiscriminantAnalysis(),\n",
    "    \n",
    "    # XGBoost\n",
    "    XGBClassifier()\n",
    "]\n",
    "\n",
    "# Split dataset in cross-validation with sklearn shuffle split. This is an alternative to train_test_split\n",
    "# run the model 10x, with a train/test split of 60/30, intentionally leaving out 10%\n",
    "cv_split = model_selection.ShuffleSplit(n_splits=10, test_size=0.3, train_size=0.6, random_state=0)\n",
    "\n",
    "# Create table to compare MLA metrics\n",
    "MLA_columns = ['MLA Name', 'MLA Parameters', 'MLA Train Accuracy Mean', 'MLA Test Accuracy Mean', 'MLA Test Accuracy 3*STD', 'MLA Time']\n",
    "MLA_compare = pd.DataFrame(columns=MLA_columns)\n",
    "\n",
    "# Create table to compare MLA predictions\n",
    "MLA_predict = data1[Target]\n",
    "\n",
    "# loop through MLA and save performance in the table\n",
    "row_index = 0\n",
    "for alg in MLA:\n",
    "    \n",
    "    # Set names and parameters\n",
    "    MLA_name = alg.__class__.__name__\n",
    "    MLA_compare.loc[row_index, 'MLA Name'] = MLA_name\n",
    "    MLA_compare.loc[row_index, 'MLA Parameters'] = str(alg.get_params())\n",
    "    \n",
    "    # Score model with cross validation\n",
    "    cv_results = model_selection.cross_validate(alg, data1[data1_x_bin], data1[Target], cv=cv_split)\n",
    "    \n",
    "    MLA_compare.loc[row_index, 'MLA Time'] = cv_results['fit_time'].mean()\n",
    "    MLA_compare.loc[row_index, 'MLA Train Accuracy Mean'] = cv_results['train_score'].mean()\n",
    "    MLA_compare.loc[row_index, 'MLA Test Accuracy Mean'] = cv_results['test_score'].mean()\n",
    "    \n",
    "    # Find std, and if this is non-bias random sample, +/- 3 stdev from mean should statistically\n",
    "    # capture 99.7% of the subsets\n",
    "    MLA_compare.loc[row_index, 'MLA Test Accuracy 3*STD'] = cv_results['test_score'].std()*3\n",
    "    \n",
    "    # Fit and predict for each MLA and save in df\n",
    "    alg.fit(data1[data1_x_bin], data1[Target])\n",
    "    MLA_predict[MLA_name] = alg.predict(data1[data1_x_bin])\n",
    "    \n",
    "    row_index += 1\n",
    "    \n",
    "# Print and sort table\n",
    "MLA_compare.sort_values(by=['MLA Test Accuracy Mean'], ascending=False, inplace=True)\n",
    "MLA_compare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a0e499c5-30d6-458a-9234-86c3ca6dbfcc",
    "_uuid": "9716581db8ff9037629a01138e5b62952f1ebd72"
   },
   "source": [
    "Plot the results of each classifier to see which one has the highest Test Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "836d82cc-023a-4c86-a70c-60445550751b",
    "_uuid": "131a4eb68d4aca37c857df780bc74ff788e8c69b",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot results of each classifier\n",
    "plt.figure(figsize=(16,12))\n",
    "sns.barplot(x='MLA Test Accuracy Mean', y='MLA Name', data=MLA_compare, color='m')\n",
    "plt.xlabel('Accuracy Score (%)')\n",
    "plt.ylabel('Algorithm');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "eb59004a-fb37-4e29-8402-32b93d189d18",
    "_uuid": "68a76e49123fa5aa467f0706fb8db248c2b88f97"
   },
   "source": [
    "# Tune Models\n",
    "\n",
    "\n",
    "**Tune model's hyper parameters**<br>\n",
    "Use ParameterGrid to get all possible combinations parameters, and then GridSearchCV. Evaluate it using sklearn scoring, ROC_AUC scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "cdab89e2-c29a-44cd-b40f-d5fc03828203",
    "_uuid": "089fa3aec7a103dd2ce58cc094013f6ea387ccc5",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Intialise base model\n",
    "dtree = tree.DecisionTreeClassifier(random_state=0)\n",
    "base_results = model_selection.cross_validate(dtree, data1[data1_x_bin], data1[Target], cv=cv_split)\n",
    "dtree.fit(data1[data1_x_bin], data1[Target])\n",
    "\n",
    "print('Before DT Parameters', dtree.get_params())\n",
    "print('Before DT Training w/bin score mean: {:.2f}'.format(base_results['train_score'].mean()*100) )\n",
    "print('Before DT Test w/bin score mean: {:.2f}'.format(base_results['test_score'].mean()*100))\n",
    "print('Before DT Test w/bin score 3*std: +/- {:.2f}'.format(base_results['test_score'].std()*100*3))\n",
    "print('-'*60)\n",
    "\n",
    "# Tune hyper parameters\n",
    "# Use Gridsearch to get run all permutations of the hyper parameters. Put permutations in dict first\n",
    "param_grid = {'criterion': ['gini', 'entropy'], 'max_depth':[2,4,6,8,10,None], 'random_state': [0]}\n",
    "\n",
    "tune_model = model_selection.GridSearchCV(tree.DecisionTreeClassifier(), param_grid=param_grid, scoring='roc_auc', n_jobs=-1, cv=cv_split)\n",
    "tune_model.fit(data1[data1_x_bin], data1[Target])\n",
    "\n",
    "print('Afrer DT Parameters', tune_model.best_params_)\n",
    "print('After DT Training w/bin score mean: {:.2f}'.format(tune_model.cv_results_['mean_train_score'][tune_model.best_index_]*100))\n",
    "print('After DT Test w/bin score mean: {:.2f}'.format(tune_model.cv_results_['mean_test_score'][tune_model.best_index_]*100))\n",
    "print('After DT Test w/bin score 3*std: +/- {:.2f}'.format(tune_model.cv_results_['std_test_score'][tune_model.best_index_]*100*3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "18e0cc16-657a-43f5-937d-5bce84e9c821",
    "_uuid": "45c64ec6ba680c1fce59c0000161c3b75d770152"
   },
   "source": [
    "**Tune model using feature selection**<br>\n",
    "More predictor variables do not make a better model, but the right predictors do. So another step in data modeling is feature selection. Sklearn has several options, we will use recursive feature elimination (RFE) with cross validation (CV) to select the best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c85f51e3-896a-48be-b736-9158d73a4e1e",
    "_uuid": "9b81e214b55f5c1a72e1b5e4c8f7835abbe4a908",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get data from base model for comparison\n",
    "print('Before DT RFE Training Shape Old', data1[data1_x_bin].shape)\n",
    "print('Before DT RFT Training Columns Old', data1[data1_x_bin].columns.values)\n",
    "\n",
    "print('Before DT RFE Training w/bin score mean: {:.2f}'.format(base_results['train_score'].mean()*100) )\n",
    "print('Before DT RFE Test w/bin score mean: {:.2f}'.format(base_results['test_score'].mean()*100))\n",
    "print('Before DT RFE Test w/bin score 3*std: +/- {:.2f}'.format(base_results['test_score'].std()*100*3))\n",
    "print('-'*60)\n",
    "\n",
    "# Feature selection\n",
    "dtree_rfe = feature_selection.RFECV(dtree, step=1, cv=cv_split, scoring='accuracy')\n",
    "dtree_rfe.fit(data1[data1_x_bin], data1[Target])\n",
    "\n",
    "# get predictors after RFE\n",
    "X_rfe = data1[data1_x_bin].columns.values[dtree_rfe.get_support()]\n",
    "\n",
    "# Use the columns, and run the dtree again scoring using CV\n",
    "rfe_results = model_selection.cross_validate(dtree, data1[X_rfe], data1[Target], cv=cv_split)\n",
    "\n",
    "# Print out results\n",
    "print('After DT RFE Training Shape New: ', data1[X_rfe].shape)\n",
    "print('After DT RFE Training Columns New: ', X_rfe)\n",
    "\n",
    "print('After DT RFE Training w/bin score mean: {:.2f}'.format(rfe_results['train_score'].mean()*100))\n",
    "print('After DT RFE Test w/bin score mean: {:.2f}'.format(rfe_results['test_score'].mean()*100))\n",
    "print('After DT RFE Test w/bin score 3*std: +/- {:.2f}'.format(rfe_results['test_score'].std()*100*3))\n",
    "print('-'*60)\n",
    "\n",
    "# Tune RFE model with gridsearch\n",
    "rfe_tune_model = model_selection.GridSearchCV(tree.DecisionTreeClassifier(), param_grid=param_grid, scoring='roc_auc', cv=cv_split)\n",
    "rfe_tune_model.fit(data1[X_rfe], data1[Target])\n",
    "\n",
    "# Print out results of tuned DT RFE model\n",
    "print('After DT RFE Parameters', rfe_tune_model.best_params_)\n",
    "print('After RFE DT Training w/bin score mean: {:.2f}'.format(rfe_tune_model.cv_results_['mean_train_score'][rfe_tune_model.best_index_]*100))\n",
    "print('After RFE DT Test w/bin score mean: {:.2f}'.format(rfe_tune_model.cv_results_['mean_test_score'][rfe_tune_model.best_index_]*100))\n",
    "print('After RFE DT Test w/bin score 3*std: +/- {:.2f}'.format(rfe_tune_model.cv_results_['std_test_score'][rfe_tune_model.best_index_]*100*3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "1dc637a1-f01b-4ea8-bd6a-7049bb9334eb",
    "_uuid": "09e350bb7b76085e67312e3dd1e53fe6eabf264b"
   },
   "source": [
    "# Validate and Implement Model\n",
    "\n",
    "Look at the correlation between models. The models with lower correlations tend to aggregate to a better ensemble model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "12567fab-41e9-4cdd-9618-a1487a3fa6a0",
    "_uuid": "7c8b0070d50bdd8b086ff8011d9632e08e445c15",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correlation_heatmap(MLA_predict)\n",
    "# the blue and light red models have low corr, can create an ensemble of models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "fedd0814-1f42-44f0-bb58-dca2cdf8f0bd",
    "_uuid": "4c8184436fefeef17b4dd96741a05551a1326ef6"
   },
   "source": [
    "**Voting Classifier**\n",
    "\n",
    "Create an ensemble using sklearn's Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "2022b10f-a556-4369-a8e9-d36462f0fb8e",
    "_uuid": "8e7ab226240da327dffdde695485948005e64497",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the list of models\n",
    "vote_est = [\n",
    "    \n",
    "    # Ensemble methods\n",
    "    ('ada', ensemble.AdaBoostClassifier()),\n",
    "    ('bc', ensemble.BaggingClassifier()),\n",
    "    ('etc', ensemble.ExtraTreesClassifier()),\n",
    "    ('gbc', ensemble.GradientBoostingClassifier()),\n",
    "    ('rfc', ensemble.RandomForestClassifier()),\n",
    "    \n",
    "    # Gaussian Processes\n",
    "    ('gpc', gaussian_process.GaussianProcessClassifier()),\n",
    "    \n",
    "    # General Linear Model\n",
    "    ('lr', linear_model.LogisticRegressionCV()),\n",
    "    \n",
    "    # Naive Bayes\n",
    "    ('bnb', naive_bayes.BernoulliNB()),\n",
    "    ('gnb', naive_bayes.GaussianNB()),\n",
    "    \n",
    "    # Nearest Neighbour\n",
    "    ('knn', neighbors.KNeighborsClassifier()),\n",
    "    \n",
    "    # SVM\n",
    "    ('svc', svm.SVC(probability=True)),\n",
    "    \n",
    "    # XGBoost\n",
    "    ('xgb', XGBClassifier())\n",
    "]\n",
    "\n",
    "# Create a hard vote ensemble (majority rules)\n",
    "vote_hard = ensemble.VotingClassifier(vote_est, voting='hard', n_jobs=-1)\n",
    "vote_hard_cv = model_selection.cross_validate(vote_hard, data1[data1_x_bin], data1[Target], cv=cv_split)\n",
    "vote_hard.fit(data1[data1_x_bin], data1[Target])\n",
    "\n",
    "# Print out results for vote hard classifier\n",
    "print('Hard voting training score mean: {:.2f}'.format(vote_hard_cv['train_score'].mean()*100))\n",
    "print('Hard voting test score mean: {:.2f}'.format(vote_hard_cv['test_score'].mean()*100))\n",
    "print('Hard voting 3*std: +/- {:.2f}'.format(vote_hard_cv['test_score'].std()*100*3))\n",
    "print('-'* 60)\n",
    "\n",
    "# Create a soft vote ensemble (weighted probabilities)\n",
    "vote_soft = ensemble.VotingClassifier(vote_est, voting='soft', n_jobs=-1)\n",
    "vote_soft_cv = model_selection.cross_validate(vote_soft, data1[data1_x_bin], data1[Target], cv= cv_split)\n",
    "vote_soft.fit(data1[data1_x_bin], data1[Target])\n",
    "\n",
    "# Print out results for soft voting classifer\n",
    "print('Soft voting training score mean: {:.2f}'.format(vote_soft_cv['train_score'].mean()*100))\n",
    "print('Soft voting test score mean: {:.2f}'.format(vote_soft_cv['test_score'].mean()*100))\n",
    "print('Soft voting 3*std: +/- {:.2f}'.format(vote_soft_cv['test_score'].std()*100*3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b8b544d9-2120-4aa3-855d-f45639b2ae2a",
    "_uuid": "0d2873e3866dd7697cf193635ac80939de9b6935"
   },
   "source": [
    "**Tune Voting Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "9ca4e0ba-c550-4383-96d2-763e383bdec5",
    "_uuid": "46cf1baf3ce167fddba50313a0b1099b7ff32adc",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Warning, running is computationally expensive\n",
    "\n",
    "grid_n_estimator = [10, 50, 100, 300]\n",
    "grid_ratio = [.1, .25, .5, .75, 1.0]\n",
    "grid_learn = [.01, .03, .05, .1, .25]\n",
    "grid_max_depth = [2, 4, 6, 8, 10, None]\n",
    "grid_min_samples = [5, 10, .03, .05, .10]\n",
    "grid_criterion = ['gini', 'entropy']\n",
    "grid_bool = [True, False]\n",
    "grid_seed = [0]\n",
    "\n",
    "grid_param = [\n",
    "    # Adaboost Classifier\n",
    "    [{\n",
    "        'n_estimators': grid_n_estimator, #default=50\n",
    "            'learning_rate': grid_learn, #default=1\n",
    "            #'algorithm': ['SAMME', 'SAMME.R'], #default=SAMME.R\n",
    "            'random_state': grid_seed\n",
    "    }],\n",
    "    \n",
    "    # Bagging Classifier\n",
    "    [{'n_estimators': grid_n_estimator,\n",
    "      'max_samples': grid_ratio,\n",
    "      'random_state': grid_seed\n",
    "    }],\n",
    "    \n",
    "    # ExtraTreesClassifier\n",
    "    [{'n_estimators': grid_n_estimator,\n",
    "      'criterion': grid_criterion,\n",
    "      'max_depth': grid_max_depth,\n",
    "      'random_state': grid_seed\n",
    "    }],\n",
    "    \n",
    "    # GradientBoostingClassifier\n",
    "    [{'learning_rate': grid_learn,\n",
    "      'n_estimators': grid_n_estimator,\n",
    "      'max_depth': grid_max_depth,\n",
    "      'random_state': grid_seed\n",
    "    }],\n",
    "    \n",
    "    # RandomForestClassifier\n",
    "    [{'n_estimators': grid_n_estimator,\n",
    "      'criterion': grid_criterion,\n",
    "      'max_depth': grid_max_depth,\n",
    "      'oob_score': [True],\n",
    "      'random_state': grid_seed\n",
    "    }],\n",
    "    \n",
    "    # GaussianProcessClassifier\n",
    "    [{'max_iter_predict': grid_n_estimator,\n",
    "    'random_state': grid_seed\n",
    "     }],\n",
    "    \n",
    "    # Logistic Regression\n",
    "    [{'fit_intercept': grid_bool,\n",
    "      'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "      'random_state': grid_seed\n",
    "    }],\n",
    "    \n",
    "    # BernoulliNB\n",
    "    [{'alpha': grid_ratio\n",
    "    }],\n",
    "    \n",
    "    # GaussianNB\n",
    "    [{}],\n",
    "    \n",
    "    # K Nearest Neighbours\n",
    "    [{'n_neighbors': [1,2,3,4,5,6,7],\n",
    "      'weights': ['uniform', 'distance'],\n",
    "      'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "    }],\n",
    "    \n",
    "    # SVM\n",
    "    [{'C': [1,2,3,4,5],\n",
    "      'gamma': grid_ratio,\n",
    "      'decision_function_shape': ['ovo', 'ovr'],\n",
    "      'probability': [True],\n",
    "      'random_state': grid_seed\n",
    "    }],\n",
    "    \n",
    "    #XGBoost\n",
    "    [{'learning_rate': grid_learn,\n",
    "      'max_depth': [1,2,4,6,8,10],\n",
    "      'n_estimators': grid_n_estimator,\n",
    "      'seed': grid_seed\n",
    "    }]\n",
    "]\n",
    "\n",
    "\n",
    "start_total = time.perf_counter()\n",
    "for clf, param in zip(vote_est, grid_param):\n",
    "    \n",
    "    start = time.perf_counter()\n",
    "    best_search = model_selection.GridSearchCV(estimator=clf[1], param_grid=param, cv=cv_split, scoring='roc_auc')\n",
    "    best_search.fit(data1[data1_x_bin], data1[Target])\n",
    "    run = time.perf_counter() - start\n",
    "    \n",
    "    best_param = best_search.best_params_\n",
    "    print('The best parameter for {} is {}, runtime: {:.2f} seconds.'.format(clf[1].__class__.__name__, best_param, run))\n",
    "    clf[1].set_params(**best_param)\n",
    "    \n",
    "run_total = time.perf_counter() - start_total\n",
    "print('Total optimization time is {:.2f} minutes'.format(run_total/60))\n",
    "print('-'*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c52af014-3e6e-4e8b-bf8b-1b81b6b15168",
    "_uuid": "16e86093f28782288ae10544035d89fb1dbe09bb",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a hard vote ensemble (majority rules)\n",
    "grid_hard = ensemble.VotingClassifier(vote_est, voting='hard', n_jobs=-1)\n",
    "grid_hard_cv = model_selection.cross_validate(grid_hard, data1[data1_x_bin], data1[Target], cv=cv_split)\n",
    "grid_hard.fit(data1[data1_x_bin], data1[Target])\n",
    "\n",
    "# Print out results for vote hard classifier\n",
    "print('Hard voting (tuned hyperparameters) training score mean: {:.2f}'.format(grid_hard_cv['train_score'].mean()*100))\n",
    "print('Hard voting (tuned hyperparameters) test score mean: {:.2f}'.format(grid_hard_cv['test_score'].mean()*100))\n",
    "print('Hard voting (tuned hyperparameters) 3*std: +/- {:.2f}'.format(grid_hard_cv['test_score'].std()*100*3))\n",
    "print('-'* 60)\n",
    "\n",
    "# Create a soft vote ensemble (weighted probabilities)\n",
    "grid_soft = ensemble.VotingClassifier(vote_est, voting='soft', n_jobs=-1)\n",
    "grid_soft_cv = model_selection.cross_validate(grid_soft, data1[data1_x_bin], data1[Target], cv= cv_split)\n",
    "grid_soft.fit(data1[data1_x_bin], data1[Target])\n",
    "\n",
    "# Print out results for soft voting classifer\n",
    "print('Soft voting (tuned hyperparameters) training score mean: {:.2f}'.format(grid_soft_cv['train_score'].mean()*100))\n",
    "print('Soft voting (tuned hyperparameters) test score mean: {:.2f}'.format(grid_soft_cv['test_score'].mean()*100))\n",
    "print('Soft voting (tuned hyperparameters) 3*std: +/- {:.2f}'.format(grid_soft_cv['test_score'].std()*100*3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "11da2eed-93cc-4147-b17a-554f988eb5d2",
    "_uuid": "b0fd1259ed11a7470e31dbaa03a0e005be3aea8b"
   },
   "source": [
    "**The tuned hard vote ensemble gives us the best test score of 82.50. Select this model on the data to predict new observations.** "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
